{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mfa-tutorial.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcGKjp1GVCqMHqILRWMdqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jundev1l2l/Machine-Learning/blob/master/mfa_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZOQvlCbS8eY"
      },
      "source": [
        "# Mixture of Factor Analysis - Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOWT-b8DTACy"
      },
      "source": [
        "# utils.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMPpBQZuTHqe"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVXo31KoTTXZ"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmg0zhxlTCIc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class Leukemia():\n",
        "    \"\"\"\n",
        "    Leukemia Dataset\n",
        "\n",
        "    attributes:\n",
        "\n",
        "\n",
        "    methods:\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        df = pd.read_excel(\"./drive/My Drive/Colab Notebooks/mfa-tutorial/leukemia.xlsx\")[1:]  # [7129, 73]\n",
        "        self.data = np.array(df.loc[2:, df.columns != \"leukemia\"]).transpose()  # [72, 7128]\n",
        "        self.cluster = np.array(df.loc[1][1:] == \"AML\").astype(float)  # [72,]\n",
        "    \n",
        "    def get_dataset(self):\n",
        "        return (self.data, self.cluster)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqLiRWH0TGSx"
      },
      "source": [
        "# model.py\n",
        "\n",
        "- MFA algorithm implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma-FxcvMfqZr"
      },
      "source": [
        "def inv(mtx):\n",
        "    return np.linalg.inv(mtx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRuZjPzxZ35W"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MFA():\n",
        "    \"\"\"\n",
        "    Mixture of Factor Analysis\n",
        "\n",
        "    attributes:\n",
        "    X, S, SS, R, M, A, V, P\n",
        "\n",
        "    methods:\n",
        "    train, _estep, _mstep, _plot, _plot_latent, _evaluation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, label, latent_dim, num_mix):\n",
        "        self.X = data\n",
        "        self.Y = label\n",
        "        self.N, self.D = data.shape\n",
        "\n",
        "        self.L, self.K = latent_dim, num_mix\n",
        "\n",
        "        self.S = np.empty((self.N, self.K, self.L))\n",
        "        self.SS = np.empty((self.N, self.K, self.L, self.L))\n",
        "        self.R = np.empty((self.N, self.K))\n",
        "        \n",
        "        self.M = np.random.uniform(low=np.min(data), high=np.max(data), size=(self.K, self.D))  # initialize with N(0,1)\n",
        "        self.A = np.random.randn(self.K, self.D, self.L)  # initialize with N(0,1)\n",
        "        self.V = np.eye(self.D)  # initialize with I\n",
        "        self.P = np.ones((self.K)) / self.K  # initialize with 1/K\n",
        "\n",
        "    def train(self, epsilon, epochs, alpha=0.3, plot=True, eval=False):\n",
        "        \"\"\"\n",
        "        repeat _estep() and _mstep() to optimize parameters\n",
        "        \"\"\"\n",
        "        for epoch in range(epochs):\n",
        "            self._estep()\n",
        "            print(f\"estep {epoch+1} done\")\n",
        "            deltaM = self._mstep()\n",
        "            print(f\"mstep {epoch+1} done with deltaM = {deltaM:0.4f}\")\n",
        "            if deltaM < epsilon:\n",
        "                print(f\"finished with deltaM = {deltaM:0.4f}\")\n",
        "                print()\n",
        "                break\n",
        "        if plot==True:\n",
        "            self._plot(True, True, alpha)\n",
        "        print()\n",
        "        self._plot_latent()\n",
        "        if eval==True:\n",
        "            print()\n",
        "            self._evaluation()\n",
        "\n",
        "    def _estep(self):\n",
        "        \"\"\"\n",
        "        update R, S, SS\n",
        "        \"\"\"\n",
        "        # R\n",
        "        for t in range(self.N):\n",
        "            for k in range(self.K):\n",
        "                exp_term = - 0.5 * (self.X[t] - self.M[k]).transpose() @ inv(self.A[k] @ self.A[k].transpose() + self.V) @ (self.X[t] - self.M[k])\n",
        "                exp_term = np.clip(exp_term, -1.0e2, 1.0e2)\n",
        "                exp_term = np.nan_to_num(exp_term, nan = 0.0)\n",
        "                self.R[t,k] = self.P[k] * np.exp(exp_term)\n",
        "        \n",
        "        self.R = self.R / np.sum(self.R, axis=1).reshape(-1,1)\n",
        "        \n",
        "        # S, SS\n",
        "        phi = np.empty((self.K, self.L, self.D))\n",
        "        for k in range(self.K):\n",
        "            phi[k] = self.A[k].transpose() @ (self.A[k] @ self.A[k].transpose() + self.V)\n",
        "        for t in range(self.N):\n",
        "            for k in range(self.K):\n",
        "                self.S[t,k] = phi[k] @ (self.X[t] - self.M[k])\n",
        "                self.SS[t,k] = np.eye(self.L) - phi[k] @ self.A[k] + phi[k] @ (self.X[t] - self.M[k]).reshape(-1,1) @ (self.X[t] - self.M[k]).reshape(-1,1).transpose() @ phi[k].transpose()\n",
        "\n",
        "    def _mstep(self):\n",
        "        \"\"\"\n",
        "        update A, M, V, P\n",
        "\n",
        "        return deltaM = Frobenius_Norm(M_new - M_old)\n",
        "        \"\"\"\n",
        "        # A\n",
        "        for k in range(self.K):\n",
        "            a, b = 0, 0\n",
        "            for t in range(self.N):\n",
        "                a += self.R[t,k] * (self.X[t] - self.M[k]).reshape(-1,1) @ self.S[t,k].reshape(-1,1).transpose()\n",
        "                b += self.R[t,k] * self.SS[t,k]\n",
        "            self.A[k] = a @ inv(b)\n",
        "        self.A = np.clip(self.A, 1e-10, 1e10)\n",
        "        self.A = np.nan_to_num(self.A, nan = 0.0)\n",
        "\n",
        "        # M\n",
        "        sum = np.sum(self.R, axis=0)\n",
        "        M_old = np.copy(self.M)\n",
        "        for k in range(self.K):\n",
        "            a = 0\n",
        "            for t in range(self.N):\n",
        "                a += self.R[t,k] * (self.X[t] - self.A[k] @ self.S[t,k]) / sum[k]\n",
        "            self.M[k] = a\n",
        "        deltaM = np.sum((self.M - M_old)**2)\n",
        "\n",
        "        # V\n",
        "        a = 0\n",
        "        for t in range(self.N):\n",
        "            for k in range(self.K):\n",
        "                a += self.R[t,k] * ((self.X[t] - self.M[k]).reshape(-1,1) @ (self.X[t] - self.M[k]).reshape(-1,1).transpose() - self.A[k] @ self.S[t,k].reshape(-1,1) @ (self.X[t] - self.M[k]).reshape(-1,1).transpose()) / self.N\n",
        "        self.V = np.diag(np.diag(a)).astype(np.float64)\n",
        "\n",
        "        # P\n",
        "        P = np.sum(self.R, axis=0) / self.N\n",
        "\n",
        "        return deltaM\n",
        "\n",
        "    def _plot(self, cluster, regression, alpha=0.3):\n",
        "        \"\"\"\n",
        "        plot clusters and regression lines\n",
        "        \"\"\"\n",
        "        print(f\"num_mix: {self.K}\")\n",
        "\n",
        "        if cluster:\n",
        "            # clustering\n",
        "            cluster_pred = np.array([1 if self.R[t][0] > 0.5 else 0 if self.R[t][0] == 0.5 else 2 for t in range(self.N)]) # [N,]\n",
        "\n",
        "            # plot data\n",
        "            data0 = self.X[cluster_pred == 0]  # not-clustered points\n",
        "            data1 = self.X[cluster_pred == 1]  # cluster1\n",
        "            data2 = self.X[cluster_pred == 2]  # cluster2\n",
        "\n",
        "            fig = plt.figure()\n",
        "            ax = fig.add_subplot(1,1,1)\n",
        "            ax.plot(data0[:,0], data0[:,1], \"k.\", alpha=alpha)\n",
        "            ax.plot(data1[:,0], data1[:,1], \"b.\", alpha=alpha)\n",
        "            ax.plot(data2[:,0], data2[:,1], \"r.\", alpha=alpha)\n",
        "            plt.plot()\n",
        "\n",
        "        if regression:\n",
        "            s1 = self.S[:,0,:]\n",
        "            s2 = self.S[:,1,:]\n",
        "            p1 = (self.A[0] @ s1.transpose()).transpose() + self.M[0]\n",
        "            p2 = (self.A[1] @ s2.transpose()).transpose() + self.M[1]\n",
        "            # [D,L] @ [L,N] = [D,N] -> transpose -> [N,D]\n",
        "\n",
        "            plt.plot(p1[:,0], p1[:,1], \"b-\")\n",
        "            plt.plot(p2[:,0], p2[:,1], \"r-\")\n",
        "        \n",
        "        plt.show()\n",
        "\n",
        "    def _plot_latent(self):\n",
        "        \"\"\"\n",
        "        plot latent points of data\n",
        "        \n",
        "        if latent_dim = 1 or 2 or 3\n",
        "        \"\"\"\n",
        "        print(f\"latent_dim: {self.L}\")\n",
        "\n",
        "        # clustering\n",
        "        cluster_pred = np.array([1 if self.R[t][0] > 0.5 else 0 if self.R[t][0] == 0.5 else 2 for t in range(self.N)]) # [N,]\n",
        "\n",
        "        # plot data\n",
        "        latent0 = self.S[cluster_pred == 0]  # not-clustered points\n",
        "        latent1 = self.S[cluster_pred == 1]  # cluster1\n",
        "        latent2 = self.S[cluster_pred == 2]  # cluster2\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(1,1,1)\n",
        "\n",
        "        if self.L == 1:\n",
        "            ax.plot(latent0[:,0], [0]*len(latent0), \"k.\")\n",
        "            ax.plot(latent1[:,0], [0]*len(latent1), \"b.\")\n",
        "            ax.plot(latent2[:,0], [0]*len(latent2), \"r.\")\n",
        "        elif self.L == 2:\n",
        "            ax.plot(latent0[:,0], latent0[:,1], \"k.\")\n",
        "            ax.plot(latent1[:,0], latent1[:,1], \"b.\")\n",
        "            ax.plot(latent2[:,0], latent2[:,1], \"r.\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def _evaluation(self):\n",
        "        p = (np.argmax(mfa.R) == mfa.Y).astype(float).mean()\n",
        "        print(f\"clustering accuracy: {max(p,1-p)}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voYk62_6TEtm"
      },
      "source": [
        "# main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7pCLDLBtP_5"
      },
      "source": [
        "## toy example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJjQG5FMHWlF"
      },
      "source": [
        "### data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKmgmOKI5CVQ"
      },
      "source": [
        "# transformation\n",
        "T1 = np.array([[3.0,0],[0,0.5]])\n",
        "T2 = np.array([[0.5,0],[0,3.0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HHHtb0qtPW3"
      },
      "source": [
        "data_toy = np.concatenate([np.random.randn(100,2) @ T1 / 2, np.random.randn(100,2)  @ T2 / 2 + np.array([5,5])], axis=0)\n",
        "cluster_toy = np.concatenate([np.zeros((100,)), np.ones((100,))], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jnDi60iu2Dk"
      },
      "source": [
        "plt.plot(data_toy[:,0], data_toy[:,1], \"k.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlPbc88VHYtz"
      },
      "source": [
        "### training, plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a1BJAIptgOK"
      },
      "source": [
        "mfa_toy = MFA(data_toy, cluster_toy, latent_dim = 1, num_mix = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nUT2RbABkz"
      },
      "source": [
        "mfa_toy.N, mfa_toy.D, mfa_toy.L, mfa_toy.K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tIfxvyruRWN"
      },
      "source": [
        "mfa_toy.train(epsilon=1e-3, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSwLHgIPHeiu"
      },
      "source": [
        "## Leukemia analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9XYDoqOHkls"
      },
      "source": [
        "### data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvQLMGLGHuRI"
      },
      "source": [
        "leukemia = Leukemia()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DXP2A_2HuRN"
      },
      "source": [
        "data, cluster = leukemia.get_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNOrIJBZHuRR"
      },
      "source": [
        "data.shape, cluster.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsElOKafJ9KW"
      },
      "source": [
        "### t-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK5guOirduHW"
      },
      "source": [
        "def t_test(data0, data1):\n",
        "    t = (data0.mean() - data1.mean()) / (data0.sum()**2/len(data0) + data1.sum()**2/len(data1))**0.5\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KqmRx1zJ9TT"
      },
      "source": [
        "data0 = data[cluster == 0]\n",
        "data1 = data[cluster == 1]\n",
        "\n",
        "t_stats = np.array([t_test(data0[:,i], data1[:,i]) for i in range(data.shape[1])])  # t-statistic values of features\n",
        "feat_index =[np.where(t_stats==t)[0][0] for t in np.sort(t_stats)[-100:]]  # index of 100 features of largest t-stats\n",
        "\n",
        "data = data[:,feat_index]  # only use selected 100 features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJMMz4JnHlo3"
      },
      "source": [
        "### training, plotting\n",
        "\n",
        "- latent dimesion = 1, 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sXHbpFJHqQN"
      },
      "source": [
        "mfa = MFA(data, cluster, latent_dim=1, num_mix=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVA0B04SKv64"
      },
      "source": [
        "mfa.N, mfa.D, mfa.L, mfa.K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uheBULd4HyMq"
      },
      "source": [
        "mfa.train(epsilon=1e-1, epochs=10, alpha=0.5, plot=False, eval=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhMFhweftNzd"
      },
      "source": [
        "mfa = MFA(data, cluster, latent_dim=2, num_mix=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnq98kx8tNzg"
      },
      "source": [
        "mfa.N, mfa.D, mfa.L, mfa.K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_dbgPc5tNzh"
      },
      "source": [
        "mfa.train(epsilon=1e-1, epochs=10, alpha=0.5, plot=False, eval=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}